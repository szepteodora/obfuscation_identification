### Obfuscation maximization for discrete choice analysis: Theory, methodology, and first empirical evidence
### The plots generated by this code are Figure 2a and 2b (informed analyst case) Figure 3a and 3b (prepared analyst case)
### 
### There are 4 Sections:
###   Settings: analyst type, sample size, and range of gamma can be adjusted here
###   Data generation (Generates the sequence of choice tasks. Sample size can be changed in settings.)
###   Generating choices +estimation (A loop for different underlying gammas. The range of gammas can be changed in settings.)
###   Creating plots (Plots the estimates and standard errors as a function of gamma.)

#install.packages(c("data.table","apollo","ggplot2","gridExtra","grid"))
library(data.table)
library(apollo)
library(ggplot2)
library(gridExtra)
library(grid)


# Settings ----------------------------------------------------------------

analyst_type <- "prepared" # options are: "naive", "informed" or "prepared"
samplesize <- 10000        # the number of choice tasks in the dataset (we use 10000 in the paper)
gammarange<-seq(0,3,.1)    # the gamma values to be tested


# Data generation ---------------------------------------------------------

set.seed(1)
resample <- function(x, ...) x[sample.int(length(x), ...)] 
K <- 2      #number of rules
J <- 3      #number of actions
Beta <- as.matrix(expand.grid(rep(list(0:2),K))) #In Beta each column stands for the according rule: B[i,j] shows to what extent rule j is followed in state i 


# Start of data generating process
dtnames <- unlist(lapply(paste0("a", c(1:J)),function(x) paste0(x, paste0("_r", c(1:K)))))


generateS <- function(rules=K, actions=J){
  S <- matrix(runif(rules*actions,min=0,max=1),nrow = rules, ncol = actions)                              
}


choicetasks <- vector("list", samplesize) 
for (i in  1:samplesize){
  choicetasks[[i]] <- data.table(t(as.vector(generateS())))
}
dt <- rbindlist(choicetasks)
setnames(dt, dtnames)


# Generating choices + estimation  ----------------------------------------

# The for loop is wrapped around choice generation and estimation as well, so that we can plot how different underlying gammas can be recovered on the same set of choice tasks

output <- vector("list", length(gammarange)) 
varcov <- vector("list", length(gammarange)) 

for (gammaval in gammarange){
  
  x <- c("naive", "informed", "prepared")
  if(all(analyst_type!=x)){stop("analyst_type should be naive, informed or prepared.")}
  
  iter=match(gammaval,gammarange)
  
  gamma <- gammaval
  followed_beta <- 8
  dt[, gamma:= gammaval]
  dt[, followed_beta:= 8] #This setting means beta1=1 and beta2=2
  
  
  for (j in 1:J){
    dt[,paste0("H_a",j):= 0]
    dt[,paste0("U_a",j):= 0]
  }
  
  
  
  for(rowindex in 1:nrow(dt)){
    dt[rowindex , ID := rowindex]
    S <- matrix(unlist(dt[rowindex,1:(K*J)]), nrow = K, ncol = J, byrow = FALSE)
    
    # U_j matrix shows that in each possible beta-scenario, what is the utility of each action
    U_j <- matrix(0, nrow = nrow(Beta), ncol = J)
    mu <- 1
    for (i in 1:nrow(Beta)){
      for (j in 1:J){
        U_j[i,j] <- (Beta[i,] %*% S[,j])*mu
      }
    }
    
    
    # Likelihood matrix: P(a_j|r_k) (if agent follows rules akkording to the ith beta, what is the percentage of choosing each action)
    P <- matrix(0, nrow = nrow(U_j), ncol = J)   
    for (i in 1:nrow(U_j)){
      for (j in 1:J){
        P[i,j]<-exp(U_j[i,j])/sum(exp(U_j[i,]))
      }
    }
    
    # Flat priors: each rule is followed with the same probability 
    P_prior <- matrix(1/nrow(Beta), nrow = 1, ncol = nrow(Beta))  
    
    # Posterior probability matrix (contains that if an action (in cols) is observed, with what probability is the rule (in rows) followed)
    P_posterior <- matrix(0, nrow = nrow(Beta), ncol = J)   
    for (i in 1:nrow(U_j)){
      for (j in 1:J){
        P_posterior[i,j] <- (P[i,j] * P_prior[i])/sum(P[,j]*P_prior[i])
      }
    }
    
    
    # The entropy of each action
    H <- matrix(0, nrow = 1, ncol = J)
    for (j in 1:J){
      entropy<-0
      for (i in 1:nrow(P_posterior)){
        if (P_posterior[i,j]!=0){entropy <- entropy+P_posterior[i,j]*log10(P_posterior[i,j])}
      }
      H[1,j] <- -entropy 
    }
    
    
    # H included as dummy variable
    H <- ifelse(H==max(H),1,H)
    H <- ifelse(H<max(H),0,H)
    
    
    U <- matrix(0, nrow = 1, ncol = J)
    for (j in 1:J){
      U[1,j] <- U_j[followed_beta,j] + gamma*H[1,j]
    }
    
    #The probabilities that need to be adjusted 
    Prob <- matrix(0, nrow = 1, ncol = J)
    for (j in 1:J){
      Prob[1,j] <- exp(U[1,j])/sum(exp(U))
    }
    
    for (j in 1:J){
      eval(parse(text = paste0("dt[rowindex,H_a",j,":= H[",j,"]]" )))
      eval(parse(text = paste0("dt[rowindex,U_a",j,":= U[",j,"]]" )))
      eval(parse(text = paste0("dt[rowindex,Prob_a",j,":= Prob[",j,"]]" )))
    }
    
    # Generating choices (simulating error term) 
    dt[rowindex,choice:=sample(c(1,2,3),1,prob=c(Prob_a1,Prob_a2,Prob_a3))]
    
    
  }
  
  
  #############Analyst
  
  ### The following deletions make sure that the data the analyst 'receives' does not contain the underlying process variables and calculations 
  
  rm(list=setdiff(ls(), c("Beta","dt","K","J", "output", "iter", "gammarange", "varcov", "gammaval", "seed", "analyst_type"))) 
  dt_original <- copy(dt) 
  
  dt[, U_a1:=NULL]
  dt[, U_a2:=NULL]
  dt[, U_a3:=NULL]
  dt[, Prob_a1:=NULL]
  dt[, Prob_a2:=NULL]
  dt[, Prob_a3:=NULL]
  dt[, followed_beta:=NULL]
  dt[, gamma:=NULL]
  
  ### Estimating the model using Apollo
  
  
  apollo_initialise()
  apollo_control = list(
    modelName ="Obfuscation_informed", 
    indivID   ="ID",     
    panelData = FALSE,    
    mixing    = FALSE,  
    nCores    = 1,      
    seed_draws= 1        
  )
  
  database  <-  dt
  
    apollo_beta=c(b_r1  = 0,
                  b_r2  = 0,
                  gamma = gammaval)
    apollo_fixed = c("gamma")
    
    if (analyst_type=="prepared" ){
      apollo_fixed = c()
    } 
  


  apollo_inputs = apollo_validateInputs()
  
  apollo_probabilities=function(apollo_beta, apollo_inputs, functionality="estimate"){
    
    apollo_attach(apollo_beta, apollo_inputs)
    on.exit(apollo_detach(apollo_beta, apollo_inputs))
    
    P = list()
    V = list()
    if (analyst_type=="naive"){
      V[['a1']]  =   (b_r1 * a1_r1  + b_r2 * a1_r2)                  
      V[['a2']]  =   (b_r1 * a2_r1  + b_r2 * a2_r2) 
      V[['a3']]  =   (b_r1 * a3_r1  + b_r2 * a3_r2) 
      
    }else{
      V[['a1']]  =   (b_r1 * a1_r1  + b_r2 * a1_r2) + gamma * H_a1                   
      V[['a2']]  =   (b_r1 * a2_r1  + b_r2 * a2_r2) + gamma * H_a2
      V[['a3']]  =   (b_r1 * a3_r1  + b_r2 * a3_r2) + gamma * H_a3 
    }

    
    
    mnl_settings = list(
      alternatives  = c(a1=1, a2=2, a3=3), 
      avail         = list(a1=1, a2=1, a3=1), 
      choiceVar     = choice,
      V             = V
    )
    
    ### Compute probabilities using MNL model
    P[['model']] = apollo_mnl(mnl_settings, functionality)
    
    P = apollo_prepareProb(P, apollo_inputs, functionality)
    return(P)
  }
  
  model = apollo_estimate(apollo_beta, apollo_fixed, apollo_probabilities, apollo_inputs)
  
  output[[iter]]<- apollo_modelOutput(model, modelOutput_settings = list(printClassical=TRUE, printPVal=TRUE, printT1=FALSE, printCovar=TRUE, printCorr=TRUE, printOutliers=TRUE,
                                                                         printChange=TRUE))
  varcov[[iter]]<-model$varcov
}

# saveRDS(output, "prepared_output.Rds")


# Creating plots ----------------------------------------------------------



dtable <- data.table(gammarange, b_r1=0, b_r2=0, gamma=0, b_r1_err=0,b_r2_err=0, gamma_err=0)

for (i in 1:length(output)){
  dtable[i, b_r1:=  output[[i]]["b_r1","Estimate"]]
  dtable[i, b_r2:=  output[[i]]["b_r2","Estimate"]]
  dtable[i, gamma:= output[[i]]["gamma","Estimate"]]
  
  dtable[i, b_r1_err :=  output[[i]]["b_r1","Std.err."]]
  dtable[i, b_r2_err :=  output[[i]]["b_r2","Std.err."]]
  dtable[i, gamma_err:=  output[[i]]["gamma","Std.err."]]
}

###
linesize<-1

estplot <- ggplot(dtable, aes(x=gammarange))+
                    geom_line(aes(y=b_r1, color=paste0("\u03B2", 1)), size=linesize) +
                    geom_line(aes(y=b_r2, color=paste0("\u03B2", 2)), size=linesize)+
                    scale_x_continuous(name="Underlying \u03B3") +
                    scale_y_continuous(name="Estimates")+
                    theme(legend.position="none")

errplot <- ggplot(dtable, aes(x=gammarange))+
                    geom_line(aes(y=b_r1_err, color=paste0("\u03B2", 1)),  size=linesize) +
                    geom_line(aes(y=b_r2_err, color=paste0("\u03B2", 2)),  size=linesize)+
                    scale_x_continuous(name="Underlying \u03B3") +
                    scale_y_continuous(name="Standard errors")+
                    theme(legend.title=element_blank())

if(analyst_type=="prepared"){
  estplot <- estplot + geom_line(aes(y=gamma, color="\u03B3"), size=linesize)
  errplot <- errplot + geom_line(aes(y=gamma_err, color="\u03B3"),  size=linesize)
} 


grid.draw(cbind(ggplotGrob(estplot), ggplotGrob(errplot), size="last"))


